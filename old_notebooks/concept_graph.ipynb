{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Network Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "import seaborn as sns"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading previously calculated dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "source": [
    "dataframe_dir = \"MediumArticles\"\n",
    "# df = pd.read_csv(f\"./data_output/{dataframe_dir}/chunks.csv\", sep=\"|\")\n",
    "df_concepts = pd.read_csv(f\"./data_output/{dataframe_dir}/concepts.csv\", sep=\"|\")\n",
    "print(df_concepts.shape)\n",
    "df_concepts.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Graph Dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph dataframe is a dataframe where every row is a connection between two nodes.\n",
    "\n",
    "It is basically an inner self join of the nodes dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "source": [
    "dfne_join = pd.merge(\n",
    "    df_concepts, df_concepts, how=\"inner\", on=\"chunk_id\", suffixes=(\"_L\", \"_R\")\n",
    ")\n",
    "\n",
    "## Remove self Loops\n",
    "self_loops_drop = dfne_join[dfne_join[\"entity_L\"] == dfne_join[\"entity_R\"]].index\n",
    "dfg = dfne_join.drop(index=self_loops_drop).reset_index()\n",
    "\n",
    "## This is our graph dataframe\n",
    "print(\"Total number of nodes = \", dfg.shape[0])\n",
    "dfg.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the graph dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original graph dataframe is too big to visualise. So we will make another dataframe for visualisation purpose.\n",
    "\n",
    "-   remove the less important nodes\n",
    "-   remove less important edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "source": [
    "## Drop nodes which are less important\n",
    "less_important_nodes = dfg[(dfg[\"importance_L\"] < 2)].index\n",
    "## Drop edges where both the nodes are less important than 5\n",
    "less_important_edges = dfg[(dfg[\"importance_L\"] < 2) & (dfg[\"importance_R\"] < 2)].index\n",
    "drops = less_important_nodes.union(less_important_edges)\n",
    "\n",
    "print(\n",
    "    \"Less important Nodes = \",\n",
    "    less_important_nodes.shape[0],\n",
    "    \"\\nLess Important Edges = \",\n",
    "    less_important_edges.shape[0],\n",
    ")\n",
    "\n",
    "## Remove these rows from the graph dataframe\n",
    "dfg_vis = dfg.drop(index=drops).reset_index()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine similar edges\n",
    "\n",
    "Group the edges between the same nodes and combine them into single edge with its weight equal to the count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "source": [
    "\n",
    "## Group and aggregate edges.\n",
    "dfg_vis = (\n",
    "    dfg_vis.groupby([\"entity_L\", \"entity_R\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"importance_L\": \"mean\",\n",
    "            \"importance_R\": \"mean\",\n",
    "            \"chunk_id\": [\",\".join, \"count\"],\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "dfg_vis.columns = [\n",
    "    \"entity_L\",\n",
    "    \"entity_R\",\n",
    "    \"importance_L\",\n",
    "    \"importance_R\",\n",
    "    \"chunks\",\n",
    "    \"count\",\n",
    "]\n",
    "\n",
    "print(\"Final Number of Edges in the Visualisation Graph = \", dfg_vis.shape[0])\n",
    "dfg_vis.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing overconnected nodes\n",
    "\n",
    "These are featured in the header and the footer of the pdf file, so they are a little too connected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "source": [
    "ind = dfg_vis[\n",
    "    dfg_vis[\"entity_L\"].isin(\n",
    "        [\"Pathways to Health Equity for the G20\", \"Accelerating Global Health\"]\n",
    "    )\n",
    "    | dfg_vis[\"entity_R\"].isin(\n",
    "        [\"Pathways to Health Equity for the G20\", \"Accelerating Global Health\"]\n",
    "    )\n",
    "].index\n",
    "dfg_vis.drop(index=ind, axis=1, inplace=True)\n",
    "print(\"Final Number of Edges  = \", dfg_vis.shape[0], \"\\nDropped edges:\", len(ind))\n",
    "dfg_vis.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a NetworkX Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate nodes\n",
    "\n",
    "Here I am grouping the graph dataframe by left node and calculating the mean importance. This way we will end up with only the unique nodes from the graph dataframe along with their weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "source": [
    "# nodes = df_graph[\"entity_L\"].unique()\n",
    "nodes = dfg_vis.groupby([\"entity_L\"]).agg({\"importance_L\": \"mean\"}).reset_index()\n",
    "nodes.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a NetworkX object with nodes and edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "source": [
    "G = nx.Graph()\n",
    "for index, row in nodes.iterrows():\n",
    "    G.add_node(row[\"entity_L\"])\n",
    "\n",
    "for index, row in dfg_vis.iterrows():\n",
    "    G.add_edge(str(row[\"entity_L\"]), str(row[\"entity_R\"]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect communities using the Girvan Newman algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "source": [
    "communities_generator = nx.community.girvan_newman(G)\n",
    "top_level_communities = next(communities_generator)\n",
    "next_level_communities = next(communities_generator)\n",
    "communities = sorted(map(sorted, next_level_communities))\n",
    "print(\"Number of Communities = \", len(communities))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add colors to nodes based on community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "source": [
    "palette = \"hls\"\n",
    "\n",
    "\n",
    "## Now add these colors to communities and make another dataframe\n",
    "def colors2Community(communities) -> pd.DataFrame:\n",
    "    ## Define a color palette\n",
    "    p = sns.color_palette(palette, len(communities)).as_hex()\n",
    "    rows = []\n",
    "    group = 0\n",
    "    for community in communities:\n",
    "        color = p.pop()\n",
    "        group += 1\n",
    "        for node in community:\n",
    "            rows += [{\"entity_L\": node, \"color\": color, \"group\": group}]\n",
    "    df_colors = pd.DataFrame(rows)\n",
    "    return df_colors\n",
    "\n",
    "\n",
    "colors = colors2Community(communities)\n",
    "\n",
    "df_nodes_colors = pd.merge(\n",
    "    nodes, colors, how=\"left\", on=\"entity_L\", suffixes=(\"_N\", \"_C\")\n",
    ")\n",
    "# nodes.head()\n",
    "df_nodes_colors.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a nodes dataframe with colors and sizes of each node.\n",
    "\n",
    "lets recreate our graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "source": [
    "G = nx.Graph()\n",
    "node_size_multiple = 6\n",
    "\n",
    "for index, row in df_nodes_colors.iterrows():\n",
    "    G.add_node(\n",
    "        row[\"entity_L\"],\n",
    "        size=row[\"importance_L\"] * node_size_multiple,\n",
    "        title=row[\"entity_L\"],\n",
    "        color=row[\"color\"],\n",
    "    )\n",
    "\n",
    "for index, row in dfg_vis.iterrows():\n",
    "    G.add_edge(\n",
    "        str(row[\"entity_L\"]),\n",
    "        str(row[\"entity_R\"]),\n",
    "        weight=row[\"count\"],\n",
    "        name=row[\"chunks\"],\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "source": [
    "graph_output_directory = \"./docs/index.html\"\n",
    "\n",
    "net = Network(\n",
    "    notebook=False,\n",
    "    bgcolor=\"#1a1a1a\",\n",
    "    cdn_resources=\"remote\",\n",
    "    height=\"900px\",\n",
    "    width=\"100%\",\n",
    "    select_menu=True,\n",
    "    font_color=\"#cccccc\",\n",
    "    # filter_menu=True,\n",
    ")\n",
    "\n",
    "net.from_nx(G)\n",
    "net.repulsion(node_distance=150, spring_length=400)\n",
    "# net.barnes_hut(gravity=-18100, central_gravity=5.05, spring_length=380)\n",
    "net.show_buttons(filter_=[\"physics\"])\n",
    "\n",
    "net.show(graph_output_directory, notebook=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAI@3111",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
